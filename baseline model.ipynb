{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib.pyplot import plot\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"/Users/leafy/Documents/ds_final_project/kag_risk_factors_cervical_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_fullna = df_full.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_fullna  #making temporary save\n",
    "df = df.convert_objects(convert_numeric=True) #turn data into numeric type for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for continuous variable\n",
    "df['Number of sexual partners'] = df['Number of sexual partners'].fillna(df['Number of sexual partners'].median())\n",
    "df['First sexual intercourse'] = df['First sexual intercourse'].fillna(df['First sexual intercourse'].median())\n",
    "df['Num of pregnancies'] = df['Num of pregnancies'].fillna(df['Num of pregnancies'].median())\n",
    "df['Smokes'] = df['Smokes'].fillna(1)\n",
    "df['Smokes (years)'] = df['Smokes (years)'].fillna(df['Smokes (years)'].median())\n",
    "df['Smokes (packs/year)'] = df['Smokes (packs/year)'].fillna(df['Smokes (packs/year)'].median())\n",
    "df['Hormonal Contraceptives'] = df['Hormonal Contraceptives'].fillna(1)\n",
    "df['Hormonal Contraceptives (years)'] = df['Hormonal Contraceptives (years)'].fillna(df['Hormonal Contraceptives (years)'].median())\n",
    "df['IUD'] = df['IUD'].fillna(0) # Under suggestion\n",
    "df['IUD (years)'] = df['IUD (years)'].fillna(0) #Under suggestion\n",
    "df['STDs'] = df['STDs'].fillna(1)\n",
    "df['STDs (number)'] = df['STDs (number)'].fillna(df['STDs (number)'].median())\n",
    "df['STDs:condylomatosis'] = df['STDs:condylomatosis'].fillna(df['STDs:condylomatosis'].median())\n",
    "df['STDs:cervical condylomatosis'] = df['STDs:cervical condylomatosis'].fillna(df['STDs:cervical condylomatosis'].median())\n",
    "df['STDs:vaginal condylomatosis'] = df['STDs:vaginal condylomatosis'].fillna(df['STDs:vaginal condylomatosis'].median())\n",
    "df['STDs:vulvo-perineal condylomatosis'] = df['STDs:vulvo-perineal condylomatosis'].fillna(df['STDs:vulvo-perineal condylomatosis'].median())\n",
    "df['STDs:syphilis'] = df['STDs:syphilis'].fillna(df['STDs:syphilis'].median())\n",
    "df['STDs:pelvic inflammatory disease'] = df['STDs:pelvic inflammatory disease'].fillna(df['STDs:pelvic inflammatory disease'].median())\n",
    "df['STDs:genital herpes'] = df['STDs:genital herpes'].fillna(df['STDs:genital herpes'].median())\n",
    "df['STDs:molluscum contagiosum'] = df['STDs:molluscum contagiosum'].fillna(df['STDs:molluscum contagiosum'].median())\n",
    "df['STDs:AIDS'] = df['STDs:AIDS'].fillna(df['STDs:AIDS'].median())\n",
    "df['STDs:HIV'] = df['STDs:HIV'].fillna(df['STDs:HIV'].median())\n",
    "df['STDs:Hepatitis B'] = df['STDs:Hepatitis B'].fillna(df['STDs:Hepatitis B'].median())\n",
    "df['STDs:HPV'] = df['STDs:HPV'].fillna(df['STDs:HPV'].median())\n",
    "df['STDs: Time since first diagnosis'] = df['STDs: Time since first diagnosis'].fillna(df['STDs: Time since first diagnosis'].median())\n",
    "df['STDs: Time since last diagnosis'] = df['STDs: Time since last diagnosis'].fillna(df['STDs: Time since last diagnosis'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for categorical variable\n",
    "df = pd.get_dummies(data=df, columns=['Smokes','Hormonal Contraceptives','IUD','STDs',\n",
    "                                      'Dx:Cancer','Dx:CIN','Dx:HPV','Dx'])\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "drop_cols = [\"Biopsy\"]\n",
    "X = data.drop(drop_cols,axis=1) \n",
    "y = data['Biopsy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "# ros = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_sample(X_train, y_train)\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "X_resampled_scaled = minmax_scale.fit_transform(X_resampled)\n",
    "X_test_scaled = minmax_scale.fit_transform(X_test)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_resampled)\n",
    "# X_resampled_scaled = scaler.transform(X_resampled)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "rid = RidgeClassifier()\n",
    "rid.fit(X_resampled_scaled, y_resampled)\n",
    "predicted = np.round(rid.predict(X_test_scaled))\n",
    "print(cohen_kappa_score(y_test, predicted))\n",
    "conf = confusion_matrix(y_test, predicted)\n",
    "label = [\"0\",\"1\"]\n",
    "sns.heatmap(conf, annot=True, xticklabels=label, yticklabels=label, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lascv = LassoCV()\n",
    "lascv.fit(X_resampled_scaled, y_resampled)\n",
    "predicted = np.round(lascv.predict(X_test_scaled))\n",
    "\n",
    "print(cohen_kappa_score(y_test, predicted))\n",
    "conf = confusion_matrix(y_test, predicted)\n",
    "label = [\"0\",\"1\"]\n",
    "sns.heatmap(conf, annot=True, xticklabels=label, yticklabels=label, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel = \"rbf\")\n",
    "svc.fit(X_resampled_scaled, y_resampled)\n",
    "predicted = svc.predict(X_test_scaled)\n",
    "print(cohen_kappa_score(y_test, predicted))\n",
    "conf = confusion_matrix(y_test, predicted)\n",
    "label = [\"0\",\"1\"]\n",
    "sns.heatmap(conf, annot=True, xticklabels=label, yticklabels=label, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 2000, class_weight=\"balanced\", random_state=None)\n",
    "rf.fit(X_resampled, y_resampled)\n",
    "predicted = rf.predict(X_test)\n",
    "print(cohen_kappa_score(y_test, predicted))\n",
    "conf = confusion_matrix(y_test, predicted)\n",
    "label = [\"0\",\"1\"]\n",
    "sns.heatmap(conf, annot=True, xticklabels=label, yticklabels=label, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn import metrics\n",
    "print(metrics.sensitivity_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ros = RandomOverSampler(random_state=0)\n",
    "# ros = SMOTE(random_state=0)\n",
    "ros = ADASYN(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "recall = np.zeros(k_folds)\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_index = 0\n",
    "rid = RidgeClassifier()\n",
    "drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "#drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data['Hinselmann'])\n",
    "# for i,j in enumerate(label):\n",
    "#     if j == 0:\n",
    "#         label[i] = -1\n",
    "test_label_all = []\n",
    "predicted_all = []\n",
    "\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "    train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data_resampled)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    rid.fit(train_data_scaled, train_label_resampled)\n",
    "    predicted = rid.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    recall[fold_index] = recall_score(test_label, predicted)\n",
    "    acc[fold_index] = rid.score(test_data_scaled, test_label)\n",
    "    test_label_all.append(test_label)\n",
    "    predicted_all.append(predicted)\n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average recall is {}\".format(np.mean(recall)))\n",
    "conf = confusion_matrix(np.hstack(test_label_all).tolist(), np.hstack(predicted_all).tolist())\n",
    "tag = [\"0\",\"1\"]\n",
    "sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "plt.title(\"Confusion Matrix (oversampled)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_index = 0\n",
    "rid = RidgeClassifier()\n",
    "drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "#drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data['Biopsy'])\n",
    "\n",
    "test_label_all = []\n",
    "predicted_all = []\n",
    "\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "#     train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    rid.fit(train_data_scaled, train_label)\n",
    "    predicted = rid.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    acc[fold_index] = rid.score(test_data_scaled, test_label)\n",
    "    \n",
    "    test_label_all.append(test_label)\n",
    "    predicted_all.append(predicted)\n",
    "    \n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "conf = confusion_matrix(np.hstack(test_label_all).tolist(), np.hstack(predicted_all).tolist())\n",
    "tag = [\"0\",\"1\"]\n",
    "sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "plt.title(\"Confusion Matrix (not oversampled)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"linear\", C=0.025)\n",
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "recall = np.zeros(k_folds)\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_index = 0\n",
    "drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "#drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data['Hinselmann'])\n",
    "test_label_all = []\n",
    "predicted_all = []\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "    train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data_resampled)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    clf.fit(train_data_scaled, train_label_resampled)\n",
    "    predicted = clf.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    recall[fold_index] = recall_score(test_label, predicted)\n",
    "    acc[fold_index] = clf.score(test_data_scaled, test_label)\n",
    "    recall[fold_index] = recall_score(test_label, predicted)\n",
    "    \n",
    "    test_label_all.append(test_label)\n",
    "    predicted_all.append(predicted)\n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average recall is {}\".format(np.mean(recall)))\n",
    "conf = confusion_matrix(np.hstack(test_label_all).tolist(), np.hstack(predicted_all).tolist())\n",
    "tag = [\"0\",\"1\"]\n",
    "sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "plt.title(\"Confusion Matrix (oversampled)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"linear\", C=0.025)\n",
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_index = 0\n",
    "drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "#drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data['Citology'])\n",
    "test_label_all = []\n",
    "predicted_all = []\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    clf.fit(train_data_scaled, train_label)\n",
    "    predicted = clf.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    acc[fold_index] = clf.score(test_data_scaled, test_label)\n",
    "    test_label_all.append(test_label)\n",
    "    predicted_all.append(predicted)\n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "conf = confusion_matrix(np.hstack(test_label_all).tolist(), np.hstack(predicted_all).tolist())\n",
    "tag = [\"0\",\"1\"]\n",
    "sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "plt.title(\"Confusion Matrix (oversampled)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma=2, C=1)\n",
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "recall = np.zeros(k_folds)\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_index = 0\n",
    "drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "#drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data['Hinselmann'])\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "    train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data_resampled)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    clf.fit(train_data_scaled, train_label_resampled)\n",
    "    predicted = clf.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    \n",
    "    recall[fold_index] = recall_score(test_label, predicted)\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    acc[fold_index] = clf.score(test_data_scaled, test_label)\n",
    "    \n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average recall is {}\".format(np.mean(recall)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=15)\n",
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "recall = np.zeros(k_folds)\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_index = 0\n",
    "drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "#drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data[\"Hinselmann\"])\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "    train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data_resampled)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    clf.fit(train_data_scaled, train_label_resampled)\n",
    "    predicted = clf.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    recall[fold_index] = recall_score(test_label, predicted)\n",
    "    acc[fold_index] = clf.score(test_data_scaled, test_label)\n",
    "    \n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average recall is {}\".format(np.mean(recall)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=6, n_estimators=200, max_features=1)\n",
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "recall = np.zeros(k_folds)\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_index = 0\n",
    "drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "#drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data['Hinselmann'])\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "    train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data_resampled)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    clf.fit(train_data_scaled, train_label_resampled)\n",
    "    predicted = clf.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    \n",
    "    recall[fold_index] = recall_score(test_label, predicted)\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    acc[fold_index] = clf.score(test_data_scaled, test_label)\n",
    "    \n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average recall is {}\".format(np.mean(recall)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "recall = np.zeros(k_folds)\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_index = 0\n",
    "drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "#drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data['Hinselmann'])\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "    train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data_resampled)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    clf.fit(train_data_scaled, train_label_resampled)\n",
    "    predicted = clf.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    recall[fold_index] = recall_score(test_label, predicted)\n",
    "    acc[fold_index] = clf.score(test_data_scaled, test_label)\n",
    "    \n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average recall is {}\".format(np.mean(recall)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "clf = svm.SVC(kernel=\"linear\", C=0.025)\n",
    "# clf = svm.SVC(gamma=2, C=1)\n",
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "recall = np.zeros(k_folds)\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "fold_index = 0\n",
    "drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "#drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data['Hinselmann'])\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "    train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data_resampled)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    train_data_scaled = pca.fit_transform(train_data_scaled)\n",
    "    test_data_scaled = pca.transform(test_data_scaled)\n",
    "    \n",
    "    clf.fit(train_data_scaled, train_label_resampled)\n",
    "    predicted = clf.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    recall[fold_index] = recall_score(test_label, predicted)\n",
    "    acc[fold_index] = clf.score(test_data_scaled, test_label)\n",
    "    \n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "print (\"average recall is {}\".format(np.mean(recall)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with ISOMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomap = Isomap(n_components=5)\n",
    "# clf = svm.SVC(kernel=\"linear\", C=0.025)\n",
    "clf = svm.SVC(gamma=2, C=1)\n",
    "k_folds = 5\n",
    "cohen_kappa = np.zeros(k_folds)\n",
    "acc = np.zeros(k_folds)\n",
    "kf = KFold(n_splits=k_folds,shuffle=True)\n",
    "\n",
    "fold_index = 0\n",
    "#drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "drop_cols = [\"Biopsy\"]\n",
    "dat = np.array(data.drop(drop_cols,axis=1))\n",
    "label = np.array(data['Citology'])\n",
    "for train_indices, test_indices in kf.split(dat):\n",
    "    print (\"FOLD {}\".format(fold_index))\n",
    "    \n",
    "    train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "    train_label, test_label = label[train_indices], label[test_indices]\n",
    "    train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "    \n",
    "    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "    train_data_scaled = minmax_scale.fit_transform(train_data_resampled)\n",
    "    test_data_scaled = minmax_scale.transform(test_data)\n",
    "    \n",
    "    train_data_scaled = isomap.fit_transform(train_data_scaled)\n",
    "    test_data_scaled = isomap.transform(test_data_scaled)\n",
    "    \n",
    "    clf.fit(train_data_scaled, train_label_resampled)\n",
    "    predicted = clf.predict(test_data_scaled)\n",
    "    print(cohen_kappa_score(test_label, predicted))\n",
    "    cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "    \n",
    "    acc[fold_index] = clf.score(test_data_scaled, test_label)\n",
    "    \n",
    "    conf = confusion_matrix(test_label, predicted)\n",
    "    tag = [\"0\",\"1\"]\n",
    "    sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "    plt.show()\n",
    "    fold_index += 1\n",
    "print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "print (\"average accuracy is {}\".format(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_knn = []\n",
    "acc_knn = []\n",
    "for i in range(1,2):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    k_folds = 5\n",
    "    cohen_kappa = np.zeros(k_folds)\n",
    "    acc = np.zeros(k_folds)\n",
    "    recall = np.zeros(k_folds)\n",
    "    \n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    fold_index = 0\n",
    "    drop_cols = [\"Hinselmann\", \"Schiller\", \"Citology\", \"Biopsy\"]\n",
    "    #drop_cols = [\"Biopsy\"]\n",
    "    dat = np.array(data.drop(drop_cols,axis=1))\n",
    "    label = np.array(data['Hinselmann'])\n",
    "    for train_indices, test_indices in kf.split(dat):\n",
    "        print (\"FOLD {}\".format(fold_index))\n",
    "\n",
    "        train_data, test_data = dat[train_indices], dat[test_indices]\n",
    "        train_label, test_label = label[train_indices], label[test_indices]\n",
    "        train_data_resampled, train_label_resampled = ros.fit_sample(train_data, train_label)\n",
    "\n",
    "        minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "        train_data_scaled = minmax_scale.fit_transform(train_data_resampled)\n",
    "        test_data_scaled = minmax_scale.transform(test_data)\n",
    "\n",
    "        clf.fit(train_data_scaled, train_label_resampled)\n",
    "        predicted = clf.predict(test_data_scaled)\n",
    "        print(cohen_kappa_score(test_label, predicted))\n",
    "        cohen_kappa[fold_index] = cohen_kappa_score(test_label, predicted)\n",
    "\n",
    "        recall[fold_index] = recall_score(test_label, predicted)\n",
    "        acc[fold_index] = clf.score(test_data_scaled, test_label)\n",
    "\n",
    "#         conf = confusion_matrix(test_label, predicted)\n",
    "#         tag = [\"0\",\"1\"]\n",
    "#         sns.heatmap(conf, annot=True, xticklabels=tag, yticklabels=tag, cmap=\"YlGnBu\")\n",
    "#         plt.show()\n",
    "        fold_index += 1\n",
    "    print (\"average cohen_kappa_score is {}\".format(np.mean(cohen_kappa)))\n",
    "    print (\"average accuracy is {}\".format(np.mean(acc)))\n",
    "    cohen_knn.append(np.mean(cohen_kappa))\n",
    "    acc_knn.append(np.mean(acc))\n",
    "    print (\"average recall is {}\".format(np.mean(recall)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(cohen_knn)\n",
    "plt.ylabel('average cohen_kappa_score')\n",
    "plt.xlabel('K')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(acc_knn)\n",
    "plt.ylabel('average accuracy')\n",
    "plt.xlabel('K')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
